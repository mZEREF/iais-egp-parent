// List of email recipients.
EMAILS_TO_NOTIFY = 'zamri@toppanecquaria.com'

DOCKER_URL = 'tcp://hub.ecquaria.com:2375'
// DOCKER_TLS_CREDENTIALS_ID =
HUB_IP = '192.168.0.228'

NEXUS_CREDENTIALS_ID = 'moh-iais-jenkins'
NEXUS_CREDENTIALS = [usernamePassword(
        credentialsId: NEXUS_CREDENTIALS_ID,
        passwordVariable: 'NEXUS_PASSWORD',
        usernameVariable: 'NEXUS_USERNAME')
]

NEXUS_GROUP='https://hub.ecquaria.com/nexus/repository/maven-mohiais-rel-sim-gdc-grp/'
NEXUS_RELEASE='https://hub.ecquaria.com/nexus/repository/maven-mohiais-rel-sim-gdc/'
NEXUS_SNAPSHOT='https://hub.ecquaria.com/nexus/repository/maven-mohiais-rel-sim-gdc/'

// JENKINS_PRIVATE_KEY_CREDENTIALS_ID = 'moh-iais-jenkins-remote.private'
// JENKINS_PRIVATE_KEY_CREDENTIALS = [file(
//         credentialsId: JENKINS_PRIVATE_KEY_CREDENTIALS_ID,
//         variable: 'JENKINS_PRIVATE_KEY')
// ]

// uses: slift -> decryption
JENKINS_PFX_CREDENTIALS = file(
        credentialsId: '487dec9d-9558-43a7-8831-c7b7214f5869',
        variable: 'JENKINS_PFX')


// uses: password for JENKINS_PFX
JENKINS_PFX_PASSWORD_CREDENTIALS = string(
        credentialsId: 'c4251176-8422-4dd5-aa36-fc9f0dfb2c6c',
        variable: 'JENKINS_PFX_PASSWORD')

// uses: slift -> decryption (certificate of sender)
JENKINS_RECEIVER_CER_CREDENTIALS = file(
        credentialsId: '129904a8-e15e-4b48-b044-d910ed7154c7',
        variable: 'JENKINS_SENDER_CER')

SONARQUBE_CREDENTIALS_ID = 'moh-iais-sonartoken'

// Working directory
TX_BUILD_FOLDER = "transfer-build"

// Downloaded files are extracted to this directory
EXTRACTED_PAYLOAD = "$TX_BUILD_FOLDER/extracted-files"

// Once verification is successful, the payload would be extracted to this directory
PROJECT_FILES = "$TX_BUILD_FOLDER/project-files"

// The encryption algorithm to use (via OpenSSL).
SYMMETRIC_KEY_ALGO = '-AES-256-CBC'

// The signing algorithm to use (via OpenSSL).
SIGN_DIGEST_ALGO = "-sha256"

AD_TOOLS_VERSION = '6cdfe5e'

// Destination directory when we do `git clone`.
CHECKOUT_DIRECTORY = 'checkouts'

// Gitlab
GITLAB_CREDENTIALS_ID = 'moh-iais-gitlab'
GITLAB_CREDENTIALS = [usernamePassword(
        credentialsId: GITLAB_CREDENTIALS_ID,
        passwordVariable: 'GIT_PASSWORD',
        usernameVariable: 'GIT_USERNAME')
]

GIT_REPOS = ['iais-egp', 'iais-qa']

GITLAB_URLS = [:]
GITLAB_URLS['iais-egp'] = 'http://${GIT_USERNAME}:${GIT_PASSWORD}@hub.ecquaria.com/gitlab/moh-iais-gdc/iais-egp.git'
GITLAB_URLS['iais-qa'] = 'http://${GIT_USERNAME}:${GIT_PASSWORD}@hub.ecquaria.com/gitlab/moh-iais-gdc/iais-qa.git'

MAVEN_LOCAL_REPO = '/var/jenkins_home/.m2_for_moh_iais_egp_mock_gdc'

// will be populated from the transfer bundle
TAG_TO_BUILD = ''
// TAG_TO_BUILD = 'AUTO_SZ_REL_20200918_FIX_06'

//Repos for pushing docker images
DOCKER_UAT_REPO = 'hub.ecquaria.com:8254'
DOCKER_PRODUCTION_REPO = 'hub.ecquaria.com:8256'

//All of their docker images have this prefix
DOCKER_IMAGENAME_PREFIX = 'docker-mohiais-egp'

// List of images in code_directory|image_name format
DOCKER_IMAGES = [
    'be-main|main-web',
    'fe-main|fe-main',
    'hcsa-licence-be|hcsa-licence',
    'hcsa-licence-fe|hcsa-application',
    'payment|egov-app',
    'systemadmin|systemadmin-web',
    'web|web'
]
// Stores meta information about images that have been built in this pipeline (i.e docker build)
DOCKER_IMAGES_META = []

// Output of clair would be grouped up here
CLAIR_OUTPUT_DIRECTORY = "clair"

// Working directory for when we're handling the cicd folder.
AUTO_DEPLOYMENT_DIRECTORY="auto-deployment"

//EDS
EDS_CREDENTIALS_ID = 'moh-iais-eds'
EDS_CREDENTIALS = [usernamePassword(
        credentialsId: EDS_CREDENTIALS_ID,
        passwordVariable: 'EDS_PASSWORD',
        usernameVariable: 'EDS_ID')
]
EDS_URL = 'http://192.168.1.119:8080'

NVD_MIRROR_URL = '192.168.4.18:24080'

// used by Katalon Runtime Engine
KATALON_OFFLINE_LICENSE_CREDENTIALS = [file(
    credentialsId: '80b49081-93ca-48cf-96ec-e53b988902ba',
    variable: 'KATALON_OFFLINE_LICENSE')
]

configurePipeline()

try{
    node{
        echo "Build started for: ${target_file}."
        cleanWs()
        initVariables()

        docker.withServer(DOCKER_URL) {
            verifyPackage()
            pushToGitlab()
            updateMavenDependencies()

            checkout()
            buildAndDeploy()
            sonarqube()
        }
    }

    qualityGate()

    node{
        docker.withServer(DOCKER_URL) {
            dependencyCheck()

            withEnv(['DOCKER_CERT_PATH=/var/jenkins_home/.docker']) {
                buildDockerImages()
                scanDockerImages()
                uploadToUAT()
            }

            deployUAT()
        }
    }

    // block progression of pipeline until deployer has test environment ready.
    if(doAutomatedTestGate()){
        node{
            currentBuild.result = 'ABORTED'
        }
        return
    }

    node{
        docker.withServer(DOCKER_URL) {
            runAutomatedTests()
        }
    }

    // block progression of pipeline until QA makes a decision.
    if(doReleaseGateToProduction()){
        node{
            currentBuild.result = 'ABORTED'
        }
        return
    }

    // // block progression of pipeline until QA makes a decision.
    // if(doGate('Release Gate to Production', 'rgtp', 'Release Gate: Release to Production?')){
    //     node{
    //         currentBuild.result = 'ABORTED'
    //     }
    //     return
    // }


    node{
        docker.withServer(DOCKER_URL) {
            withEnv(['DOCKER_CERT_PATH=/var/jenkins_home/.docker']) {
                uploadToProduction()
            }

            deployProduction()
        }
    }
}
catch(err){
    println "Build caught an exception: ${err.getMessage()}"

    currentBuild.result = 'FAILURE'
}
finally{
    sendEmailNotification()
}

/**
 * Programatically configures the build.
 *
 * Curent list of items configured:
 *  (1) Concurrent builds are disabled.
 *  (2) Project should accept these parameters:
 *      (a) target_file
 */
def configurePipeline(){
    properties(
            [
                    [$class: 'JiraProjectProperty'],
                    disableConcurrentBuilds(),
                    parameters(
                            [string(
                                    defaultValue: '',
                                    description: '',
                                    name: 'target_file',
                                    trim: true)]
                    )
            ])
}

def verifyPackage(){
    stage('Verify Package'){
        sh """
            mkdir -p "$EXTRACTED_PAYLOAD"
        """
        docker
                .image("hub.ecquaria.com/ecq/ad-tools:$AD_TOOLS_VERSION")
                .inside(getDockerArgs()){
                    //grab the file from nexus first
                    withCredentials(NEXUS_CREDENTIALS) {
                        sh """
                        curl \
                        --insecure \
                        --user '${NEXUS_USERNAME}:${NEXUS_PASSWORD}' \
                        https://hub.ecquaria.com/nexus/repository/moh-iais-gdc-raw-hosted/${target_file} \
                        -o ${target_file}
                    """
                    }

                    withCredentials([JENKINS_PFX_CREDENTIALS, JENKINS_PFX_PASSWORD_CREDENTIALS, JENKINS_RECEIVER_CER_CREDENTIALS]) {
                        sh """
                        (
                            cd "/slift/" || exit
                            
                            ./run.sh \
                                -d "${env.WORKSPACE}/$target_file" "${env.WORKSPACE}/$EXTRACTED_PAYLOAD/project-files-with-approval.tar" \
                                -pfx "$JENKINS_PFX" "$JENKINS_PFX_PASSWORD" \
                                -verbose \
                                -cer "$JENKINS_SENDER_CER"
                        )

                        cd "${env.WORKSPACE}/$EXTRACTED_PAYLOAD"

                        # once payload is decrypted, extract it.
                        mkdir -p "project-files-with-approval"
                        tar -xf "project-files-with-approval.tar" -C "project-files-with-approval"

                        rm project-files-with-approval.tar

                        # change directory
                        cd project-files-with-approval

                        # re-create hash here
                        md5sum project-files.tar | awk '{ print \$1 }' > "project-files.hash"

                        basename \$(find . -type f -name "*.signature") .signature > "$WORKSPACE/$TX_BUILD_FOLDER/signed-by"
                    """
                    }

                    def signedById = readFile "$WORKSPACE/$TX_BUILD_FOLDER/signed-by"
                    signedById = signedById.replace("\n", "")

                    def credA = file(credentialsId: "${signedById}.public", variable: 'SIGNERS_PUBLIC_KEY')

                    withCredentials([credA]) {
                        sh """
                    SIGNATURE_FILE=\$(find "$TX_BUILD_FOLDER" -type f -name "*.signature")
                    HASH_FILE=\$(find "$TX_BUILD_FOLDER" -type f -name "*.hash")

                    openssl dgst "$SIGN_DIGEST_ALGO" -verify "$SIGNERS_PUBLIC_KEY" -signature "\$SIGNATURE_FILE" "\$HASH_FILE"
                    """
                    }
                }
    }
}

def pushToGitlab(){
    stage('Extract Git Bundle & Update'){
        sh """

            mkdir -p "$PROJECT_FILES"

            # extract the (verified) project files
            #find . -type f -name "project-files.tar" -print0 -quit | xargs -i -0 tar -xf '{}' -C "$PROJECT_FILES"
            tar -xf "$EXTRACTED_PAYLOAD/project-files-with-approval/project-files.tar" -C "$PROJECT_FILES"

            rm -rf "$EXTRACTED_PAYLOAD"
        """

        def dockerArgs = [
                "--entrypoint=''",
                "--add-host=\"hub.ecquaria.com:${HUB_IP}\"",
                "-e TZ=Asia/Singapore",
                // "-u 0"
        ]

        withCredentials(GITLAB_CREDENTIALS) {
            docker
                .image('hub.ecquaria.com/alpine/git:1.0.7')
                .inside(dockerArgs.join(" ")) {
                    sh """
                        mkdir -p "$CHECKOUT_DIRECTORY"
                    """

                    for (codeRepo in GIT_REPOS){
                        def bundleFile = "${env.WORKSPACE}/${PROJECT_FILES}/${codeRepo}.bundle"
                        sh """
                            git clone --quiet -c advice.detachedHead=false ${GITLAB_URLS[codeRepo]} ${CHECKOUT_DIRECTORY}/${codeRepo}
                            cd ${CHECKOUT_DIRECTORY}/${codeRepo}

                            git config user.email "mohiais@nowhere.com"
                            git config user.name "moh-iais"

                            if [[ -f ${bundleFile} ]]; then
                                git bundle verify ${bundleFile}
                                git remote add ecq-sync ${bundleFile}
                                git remote show
                                git fetch ecq-sync --tags
                                git push origin --tags
                            fi
                        """
                    }
                }
        }
    }
}

def updateMavenDependencies(){
    stage('Update Maven Dependencies'){
        def m2_tar = "${env.WORKSPACE}/${PROJECT_FILES}/m2.tar"
        sh """
            cd
            if [[ -f ${m2_tar} ]]; then
                cd ${MAVEN_LOCAL_REPO}
                tar -xf ${m2_tar} --strip=7
            fi
        """
    }

}

def getDockerArgs(){
    def dockerArgs = [
            "--entrypoint=''",
            "--add-host=\"hub.ecquaria.com:${HUB_IP}\"",
            "-e TZ=Asia/Singapore"
    ]
    dockerArgs.join(" ")
}

//init of variables used throughout the whole pipeline
def initVariables(){
    CHECKOUT_DIRECTORY = "${env.WORKSPACE}/checkouts"
}

/**
 * Differences with CI's checkout():
 * (1) We already cloned the repository before this, since we had to handle the bundle.
 * (2) We'll now need to figure out what is our TAG_TO_BUILD;
 * (3) and based on that value, we'll create a new branch to work on.
 */
def checkout(){
    stage('Checkout'){
        TAG_TO_BUILD = readFile "$WORKSPACE/$TX_BUILD_FOLDER/project-files/tag-to-build.txt"
        TAG_TO_BUILD = TAG_TO_BUILD.trim()
        printf "Retrieved value for TAG_TO_BUILD: [%s]", TAG_TO_BUILD

        // don't need this since we are not authenticating with remote
        // withCredentials(GITLAB_CREDENTIALS) {
            docker
                .image('hub.ecquaria.com/alpine/git:1.0.7')
                .inside(getDockerArgs()){
                    sh """
                        cd "$CHECKOUT_DIRECTORY/iais-egp"

                        git checkout "$TAG_TO_BUILD"

                        cd "$CHECKOUT_DIRECTORY/iais-qa"

                        git checkout "$TAG_TO_BUILD"
                    """
                }
        // }
    }
}

def buildAndDeploy(){
    stage('Build & Deploy'){

        withCredentials(NEXUS_CREDENTIALS) {

            passwordVariable: 'NEXUS_PASSWORD'
            usernameVariable: 'NEXUS_USERNAME'

            docker
                .image('hub.ecquaria.com/maven:3.6.3-jdk-8')
                .inside(getDockerArgs()){
                    withCredentials(NEXUS_CREDENTIALS) {
                        sh """
                            cd "${CHECKOUT_DIRECTORY}/iais-egp"

                            mvn \
                                --no-transfer-progress \
                                -Dmaven.repo.local=${MAVEN_LOCAL_REPO} \
                                -P "!sg-nexus,cicd-sg-nexus" \
                                -s settings-cicd-sg.xml \
                                -Dmoh.iais.nexus.username="$NEXUS_USERNAME" \
                                -Dmoh.iais.nexus.password="$NEXUS_PASSWORD" \
                                -Dsg.nexus.group.repo="$NEXUS_GROUP" \
                                -Dsg.nexus.release.repo="$NEXUS_RELEASE" \
                                -Dsg.nexus.snapshot.repo="$NEXUS_SNAPSHOT" \
                                clean deploy
                        """
                    }
                }
        }
    }
}

/**
 * Perform static code analysis via SonarQube.
 */
def sonarqube(){
    stage('SonarQube Analysis'){
        withSonarQubeEnv(credentialsId: SONARQUBE_CREDENTIALS_ID){
            docker
                .image('hub.ecquaria.com/maven:3.6.3-jdk-8')
                .inside(getDockerArgs()){
                    withCredentials(NEXUS_CREDENTIALS) {
                        sh """
                            cd "${CHECKOUT_DIRECTORY}/iais-egp"

                            mvn \
                                --no-transfer-progress \
                                -Dmaven.repo.local=${MAVEN_LOCAL_REPO} \
                                -Dsonar.projectKey=iais-iais-egp-rel \
                                -Dsonar.projectName=iais-iais-egp-rel \
                                -P "!sg-nexus,cicd-sg-nexus" \
                                -s settings-cicd-sg.xml \
                                -Dmoh.iais.nexus.username="$NEXUS_USERNAME" \
                                -Dmoh.iais.nexus.password="$NEXUS_PASSWORD" \
                                -Dsg.nexus.group.repo="$NEXUS_GROUP" \
                                -Dsg.nexus.release.repo="$NEXUS_RELEASE" \
                                -Dsg.nexus.snapshot.repo="$NEXUS_SNAPSHOT" \
                                sonar:sonar
                        """
                    }
                }
        }
    }
}

def dependencyCheck() {
    stage("Dependency Check") {
        def cliArgs = [
                "--scan ${CHECKOUT_DIRECTORY}/**/*.jar",
                "--format HTML",
                "--format XML",
                "--disableNodeJS",
                "--disableNodeAudit",
                "--disableNodeAuditCache",
                "--cveUrlModified http://${NVD_MIRROR_URL}/nvdcve-1.1-modified.json.gz",
                "--cveUrlBase http://${NVD_MIRROR_URL}/nvdcve-1.1-%d.json.gz"
        ]

        println "Dependency Check Arguments: \n${cliArgs}"

        // Note that we using the installed tool instead of going the Docker container route.
        // This is because, integration to Jenkins would be handled by the plugin.
        dependencycheck additionalArguments: cliArgs.join(" "), odcInstallation: 'latest'
        dependencyCheckPublisher pattern: 'dependency-check-report.xml', unstableTotalCritical: 13, unstableTotalHigh: 34, unstableTotalMedium: 119, unstableTotalLow: 10

        archiveArtifacts 'dependency-check-report.html'
    }
}

/**
 * Refer to https://docs.sonarqube.org/latest/analysis/scan/sonarscanner-for-jenkins/#header-6
 * for more details (i.e prerequisite, implementation details).
 *
 * The "sleep" is there to work around an issue (probabyl for a race condition). Refer to
 * https://community.sonarsource.com/t/need-a-sleep-between-withsonarqubeenv-and-waitforqualitygate-or-it-spins-in-in-progress/2265
 * for more details.
 */
def qualityGate(){
    stage("Quality Gate"){
        sleep(10)

        timeout(time: 1, unit: 'HOURS') {
            def qg = waitForQualityGate()
            if (qg.status != 'OK') {
                error "Pipeline aborted due to quality gate failure: ${qg.status}"
            }
        }
    }
}

def buildDockerImages(){
    stage('Build Docker Images'){
        def imageTag = "${TAG_TO_BUILD}-b${BUILD_NUMBER}"

        for (image in DOCKER_IMAGES) {
            def codeDir = image.split("\\|")[0]
            def imageName = DOCKER_IMAGENAME_PREFIX + '/' + image.split("\\|")[1]
            def dockerImage = docker.build("${imageName}","--force-rm --quiet -f ${CHECKOUT_DIRECTORY}/iais-egp/${codeDir}/Dockerfile_SG ${CHECKOUT_DIRECTORY}/iais-egp/${codeDir}")

            def imgMeta = [:]
            imgMeta.put('basename', dockerImage.id)
            imgMeta.put('basename-with-tag', "${dockerImage.id}:${imageTag}")
            imgMeta.put('basename-with-tag-for-uat', "${dockerImage.id}:${imageTag}-UAT")
            imgMeta.put('basename-with-tag-for-prod', "${dockerImage.id}:${imageTag}-PROD")

            // we do a tag from xxx to xxx:${imageTag} -- just to keep track of it accurately...
            dockerImage.tag("${imageTag}")

            println imgMeta

            // add to the list of docker images built
            DOCKER_IMAGES_META.push(imgMeta)
        }
    }
}

/**
 * Perform static analysis of vulnerabilities in appc and docker containers via Clair.
 *
 * Before scanning can begin, we'll need to start up 3 containers:
 *  - (1) clair db (think of it as vulnerability definitions)
 *  - (2) clair server
 *  - (3) clair client
 *
 * These 3 containers are linked via the 'clair' network.
 */
def scanDockerImages(){
    stage("Scan Docker Images"){

        //give the containers & network unique names in case other build jobs are running clair
        def suffix = "gdc-iais-egp-b${BUILD_NUMBER}"
	def clairNetworkName = "clair_${suffix}"
	def clairDbName = "postgres_${suffix}"
	def clairSvrName = "clairSvr_${suffix}"

        // recreate the clair output directory
        sh "rm -rf ${CLAIR_OUTPUT_DIRECTORY}; mkdir -p ${CLAIR_OUTPUT_DIRECTORY};"

        // declare clair images (yes, we are going bleeding edge!)
        def clairDB = docker.image('hub.ecquaria.com/arminc/clair-db:latest')
        def clairServer = docker.image('hub.ecquaria.com/arminc/clair-local-scan:v2.1.7_5125fde67edee46cb058a3feee7164af9645e07d')
        def clairClient = docker.image('hub.ecquaria.com/objectiflibre/clair-scanner:latest')

        //to force grab the latest
        clairDB.pull()

        def clairDBContainer
        def clairServerContainer

        try{

            sh "docker network create ${clairNetworkName}"

            def dockerArgs = [
                    "--network=${clairNetworkName}",
                    "--name=${clairDbName}"
            ]

            // (1/3) start clair database
            clairDBContainer = clairDB.run(dockerArgs.join(" "))
            sleep 15 // this is a hack -- give time for DB to be ready.

            // (2/3) start clair server
            dockerArgs = [
                    "--network=${clairNetworkName}",
                    "--name=${clairSvrName}",
                    "--link=${clairDbName}:postgres"
            ]
            clairServerContainer = clairServer.run(dockerArgs.join(" "))
            sleep 15 // this is a hack -- give time for server to be ready.

            // (3/3) start clair scanner
            dockerArgs = [
                    "--network=${clairNetworkName}",
                    "--entrypoint=''",
                    "--add-host=\"hub.ecquaria.com:${HUB_IP}\"",
                    "-e=\"DOCKER_HOST=${DOCKER_URL}\""
            ]
            // docker.withRegistry("https://${DOCKER_BUILD_REPO}", NEXUS_CREDENTIALS_ID){
                clairClientContainer = clairClient.inside(dockerArgs.join(" ")){
                    DOCKER_IMAGES_META.each{imgMeta ->
                        // only used to name the log file generated.
                        def fileName = "${imgMeta['basename-with-tag'].replace('/', '_')}"
                        // commands to run in the container
                        // reference to severity here: https://github.com/quay/clair/blob/master/database/severity.go
                        def dockerCmds = [
                                'clair',
                                '--ip="$(hostname -i)"',
                                "--log=${CLAIR_OUTPUT_DIRECTORY}/${fileName}.log",
                                "--report=${CLAIR_OUTPUT_DIRECTORY}/${fileName}.json",
                                '--threshold="Defcon1"',
                                "--clair=http://${clairSvrName}:6060",
                                "${imgMeta['basename-with-tag']}"
                        ]
                        sh "${dockerCmds.join(' ')} &> /dev/null"
                    }
                }
            // }
        }
        catch(err){
            println "Caught ${err}"
            throw err
        }
        finally{
            archiveArtifacts allowEmptyArchive: true, artifacts: "$CLAIR_OUTPUT_DIRECTORY/**"
            if(clairDBContainer){
                println "Manually stopping Clair DB container."
                clairDBContainer.stop()
            }
            if(clairServerContainer){
                println "Manually stopping Clair Server container."
                clairServerContainer.stop()
            }
            sh "docker network rm ${clairNetworkName}"
        }
    }
}

def uploadToUAT(){
    stage('Push to UAT Repository'){
        DOCKER_IMAGES_META.each{imgMeta ->
            // Name of the image we want to re-tag for use in UAT.
            def sourceImage = imgMeta['basename-with-tag']
            // Final name of the image we'll use in UAT.
            // def destinationImage = "${DOCKER_UAT_REPO}/${imgMeta['basename-with-tag']}-UAT"
            def destinationImage = "${DOCKER_UAT_REPO}/${imgMeta['basename-with-tag-for-uat']}"

            // Update the image's meta information.
            imgMeta.put('with-repo-tagged-for-uat', destinationImage)

            // (1) Re-tag sourceImage to destinationImage.
            // (2) Re-tag destinationImage to itself, but without the repository information.
            //     The repository information will be added again later during the push.
            sh """\
                docker tag ${sourceImage} ${destinationImage}
                docker tag ${destinationImage} ${imgMeta['basename-with-tag-for-uat']}
            """.stripIndent()

            // Login to the repository.
            docker.withRegistry("https://${DOCKER_UAT_REPO}", NEXUS_CREDENTIALS_ID){
                // Push the UAT image to the repository.
                docker.image(imgMeta['basename-with-tag-for-uat']).push()
            }

            // Print out meta information available for the image.
            println imgMeta
        }
    }
}

def uploadToProduction(){
    stage('Push to Production Repository'){
        DOCKER_IMAGES_META.each{imgMeta ->
            // Name of the image we want to re-tag for use in production.
            def sourceImage = imgMeta['with-repo-tagged-for-uat']
            // Final name of the image we'll use in production.
            def destinationImage = "${DOCKER_PRODUCTION_REPO}/${imgMeta['basename-with-tag-for-prod']}"

            // Update the image's meta information.
            imgMeta.put('with-repo-tagged-for-prod', destinationImage)

            // Login to the UAT repository.
            docker.withRegistry("https://${DOCKER_UAT_REPO}", NEXUS_CREDENTIALS_ID){
                // (1) Pull the image from the production repository.
                // (2) Re-tag sourceImage to destinationImage.
                // (3) Re-tag destinationImage to itself, but without the repository information.
                //     The repository information will be added again later during the push.
                sh """\
                    docker pull ${sourceImage}
                    docker tag ${sourceImage} ${destinationImage}
                    docker tag ${destinationImage} ${imgMeta['basename-with-tag-for-prod']}
                """.stripIndent()
            }

            // Login to the production repository.
            docker.withRegistry("https://${DOCKER_PRODUCTION_REPO}", NEXUS_CREDENTIALS_ID){
                // Push the Production image to the repository.
                docker.image(imgMeta['basename-with-tag-for-prod']).push()
            }

            // Print out meta information available for the image.
            println imgMeta
        }
    }
}

def deployUAT() {
    stage("Push UAT Deployment Package to EDS") {
        def dockerArgs = [
            "--entrypoint=''",
            "-e TZ=Asia/Singapore"
        ]

        docker
            .image("hub.ecquaria.com/ecq/ad-tools:$AD_TOOLS_VERSION")
            .inside(dockerArgs.join(" ")){
                withCredentials(EDS_CREDENTIALS) {
                    sh """
                        cd "$PROJECT_FILES"

                        rm -rf "$AUTO_DEPLOYMENT_DIRECTORY"
                        mkdir -p "$AUTO_DEPLOYMENT_DIRECTORY"

                        tar -xf auto-deployment.tar -C "$AUTO_DEPLOYMENT_DIRECTORY"

                        if [[ -d $AUTO_DEPLOYMENT_DIRECTORY/*/deploy/UAT_INTRANET ]]; then

                            (cd $AUTO_DEPLOYMENT_DIRECTORY/*/deploy/UAT_INTRANET; zip -r /tmp/archive-iais-intranet.zip *)

                            EDS_URL="$EDS_URL" \\
                            FILE_TO_UPLOAD=/tmp/archive-iais-intranet.zip \\
                            /scripts/deploy-to-eds.sh

                        fi

                        if [[ -d $AUTO_DEPLOYMENT_DIRECTORY/*/deploy/UAT_INTERNET ]]; then

                            (cd $AUTO_DEPLOYMENT_DIRECTORY/*/deploy/UAT_INTERNET; zip -r /tmp/archive-iais-internet.zip *)

                            EDS_URL="$EDS_URL" \\
                            FILE_TO_UPLOAD=/tmp/archive-iais-internet.zip \\
                            /scripts/deploy-to-eds.sh

                        fi
                    """
                }
            }
    }
}

def deployProduction() {
    stage("Push Production Deployment Package to EDS") {
        def dockerArgs = [
            "--entrypoint=''",
            "-e TZ=Asia/Singapore"
        ]

        docker
            .image("hub.ecquaria.com/ecq/ad-tools:$AD_TOOLS_VERSION")
            .inside(dockerArgs.join(" ")){
                withCredentials(EDS_CREDENTIALS) {
                    sh """
                        cd "$PROJECT_FILES"

                        # the auto-deployment folder would be handled by the previous deploy stage.

                        if [[ -d $AUTO_DEPLOYMENT_DIRECTORY/*/deploy/PROD_INTRANET ]]; then

                            (cd $AUTO_DEPLOYMENT_DIRECTORY/*/deploy/PROD_INTRANET; zip -r /tmp/archive-iais-intranet.zip *)

                            EDS_URL="$EDS_URL" \\
                            FILE_TO_UPLOAD=/tmp/archive-iais-intranet.zip \\
                            /scripts/deploy-to-eds.sh

                        fi

                        if [[ -d $AUTO_DEPLOYMENT_DIRECTORY/*/deploy/PROD_INTERNET ]]; then

                            (cd $AUTO_DEPLOYMENT_DIRECTORY/*/deploy/PROD_INTERNET; zip -r /tmp/archive-iais-internet.zip *)

                            EDS_URL="$EDS_URL" \\
                            FILE_TO_UPLOAD=/tmp/archive-iais-internet.zip \\
                            /scripts/deploy-to-eds.sh

                        fi
                    """
                }
            }
    }
}

def doAutomatedTestGate(){
    def stageName = 'Proceed Automation Test?'
    def inputId = 'atGate'
    def message = 'Proceed with automated testing?'
    def yesText = 'Proceed - Environment is ready'
    def noText = 'Reject this build'
    def choiceDescription = '''\
                            To continue with automated testing, choose to proceed and click on the submit button.
                            To reject this build, choose reject and click on the submit button.
                        '''.stripIndent()
    def commentDescription = '''\
                            Comments submitted here would be recorded (unless "Abort" was used).
                        '''.stripIndent()

    doGate(stageName, inputId, message,
        yesText, noText,
        choiceDescription, commentDescription)
}

def doReleaseGateToProduction(){
    def stageName = 'Release Gate to Production'
    def inputId = 'rgtp'
    def message = 'Release Gate: Release to Production?'
    def yesText = 'Endorse this build'
    def noText = 'Reject this build'
    def choiceDescription = '''\
                            To continue this build, choose endorse and click on the submit button.
                            To reject this build, choose reject and click on the submit button.
                        '''.stripIndent()
    def commentDescription = '''\
                            Comments submitted here would be recorded (unless "Abort" was used).
                        '''.stripIndent()

    doGate(stageName, inputId, message,
        yesText, noText,
        choiceDescription, commentDescription)
}

/**
 * Pipeline should only proceed if value returned is false.
 *
 * This method will return false only if CHOICES_YES and 'Submit' is used.
 *
 * @param stageName - Specify the name of the stage to be displayed.
 * @param inputId - Specify the input id for the dialog - (for now) only used internally by plugin.
 * @param message - Specify the message that would be displayed.
 */
def doGate(String stageName, String inputId, String message,
            String yesText, String noText, String choiceDescription, String commentDescription){
    def denied = false
    stage(stageName){
        def CHOICES_NONE = '- Please Select -'
        def CHOICES_YES = yesText
        def CHOICES_NO = noText

        def PARAMETER_CHOICE = 'Decision'
        def PARAMETER_COMMENTS = 'Comments'

        def _gate
        def _choice
        def _comments

        def getAnswer = true
        while(getAnswer){
            _gate = input id: inputId,
                    message: message,
                    ok: 'Submit',
                    parameters: [
                            choice(choices: [CHOICES_NONE, CHOICES_YES, CHOICES_NO],
                                    description: choiceDescription,
                                    name: PARAMETER_CHOICE),
                            string(defaultValue: '',
                                    description: commentDescription,
                                    name: PARAMETER_COMMENTS, trim: true)
                    ],
                    submitterParameter: 'submitter'

            // will only continue if 'Abort' was not used.
            _choice = _gate[PARAMETER_CHOICE]
            _comments = _gate[PARAMETER_COMMENTS]

            getAnswer = _choice.equals(CHOICES_NONE)
            if(getAnswer){
                println "Please make a decision before clicking on the submit button."
            }
        }

        println "Decision made at ${stageName} stage: ${_choice}"
        println "Comments given ${stageName} stage: ${_comments}"

        if(_choice.equals(CHOICES_NO)){
            denied = true
        }
    }
    return denied
}

def runAutomatedTests(){
    stage('Run Automated Tests'){
        def dockerArgs        

        try{
            withCredentials(KATALON_OFFLINE_LICENSE_CREDENTIALS) {
                // invoke katalon
                dockerArgs = [
                    "--entrypoint=''",
                    "-e KATALON_USER_ID=1000",
                    "-e TZ=Asia/Singapore",
                    "-u root",
                    "--add-host=egp.sit.inter.iais.com:192.168.1.229",
                    "--add-host=egp.sit.intra.iais.com:192.168.0.222"
                ]

                docker
                    .image('hub.ecquaria.com/ecq/katalonstudio/katalon:7.8.2-ffmpeg')
                    .inside(dockerArgs.join(" ")){
                        // def browserType = 'Chrome'
                        def browserType = 'Chrome (headless)'
                        sh """
                            mkdir -p ~/.katalon/license/ && \
                                ln -s "$KATALON_OFFLINE_LICENSE" ~/.katalon/license/offline.lic || \
                                exit \$?

                            xvfb-run -s '-screen 0 1920x1080x24' \
                            katalonc \
                                -noSplash \
                                -runMode=console \
                                -projectPath="${CHECKOUT_DIRECTORY}/iais-qa/moh_iais.prj" \
                                -retry=0 \
                                -testSuitePath="Test Suites/Automation Test Suite - SG_SIT" \
                                -executionProfile="SG_SIT" \
                                -browserType="$browserType" \
                                -remoteWebDriverUrl="http://192.168.0.228:4444/wd/hub" \
                                -remoteWebDriverType="Selenium"                            
                        """
                    }
            }
        }
        catch(e){
            println "Exception caught while running automated testing: ${e.getMessage()}"
            throw e
        }
        finally {
            sh """
                rm -f katalon-reports.zip
            """

            def REPORTS_FOLDER = "${CHECKOUT_DIRECTORY}/iais-qa/Reports"
            if ( fileExists(REPORTS_FOLDER) ) {
                zip archive: true, dir: "${REPORTS_FOLDER}", glob: '', zipFile: 'katalon-reports.zip'
            }
            else {
                println "There are no Katalon reports generated -- ${REPORTS_FOLDER} folder does not exist. "
            }
		}
    }
}

def sendEmailNotification(){
    def subjectHeader = ""
    def emailBody = ""

    if (currentBuild.result == 'SUCCESS'){
        subjectHeader = "Build succeeded: ${currentBuild.fullDisplayName}"
        emailBody = "Build succeeded, see ${env.BUILD_URL}"
    }
    else if (currentBuild.result == 'FAILURE'){
        subjectHeader = "Build failed: ${currentBuild.fullDisplayName}"
        emailBody = "Something went wrong with ${env.BUILD_URL}"
    }
    else if (currentBuild.result == 'ABORTED')
    {
        subjectHeader = "Build aborted: ${currentBuild.fullDisplayName}"
        emailBody = "Build aborted, see ${env.BUILD_URL}"
    }
    else if (currentBuild.result == 'UNSTABLE')
    {
        subjectHeader = "Build unstable: ${currentBuild.fullDisplayName}"
        emailBody = "Build unstable, see ${env.BUILD_URL}"
    }
    else{
        println "Email for build result -> [${currentBuild.result}], not handled yet."
    }


    // send email
    mail to: EMAILS_TO_NOTIFY, subject: subjectHeader, body: emailBody
}
